## Web Scraper for OPEX Week Speakers

This repository contains a web scraper that collects data on the speakers from OPEX Week and organizes it into a CSV file. The scraper was built using Python and various libraries such as BeautifulSoup, Pandas, and Asyncio.

### Dataset

The dataset created by this scraper can be found at: https://www.kaggle.com/datasets/asaniczka/2024-opex-week-speakers-data.

### Task Description

The primary task of this web scraper is to extract comprehensive information about the users listed on the OPEX Week website and organize this data into a well-structured CSV file. 

The scraper is designed to collect data such as user names, contact information, profiles, and any other pertinent details available publicly.

### Key Responsibilities

#### Data Extraction:
- The scraper extracts all relevant user data from the OPEX Week website, ensuring accuracy and completeness.
#### Data Organization: 
- The extracted data is structured into a CSV format with clear and concise column headers for easy understanding and navigation. The data is organized in a logical and user-friendly manner.
#### Quality Assurance: 
- Thorough checks are conducted to ensure data integrity and accuracy. Any errors or inconsistencies in the data are rectified promptly.

### How to Use

To use this web scraper, follow these steps:

1. Clone this repository to your local machine.
2. Install the required libraries by running `pip install -r requirements.txt.`
3. Execute the `speaker_scraper.py` file using Python.
4. The web scraper will collect the data and save it as a CSV file named OPEX_speakers.csv in the project's data folder.
